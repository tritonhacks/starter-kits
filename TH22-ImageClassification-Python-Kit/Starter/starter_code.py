# -*- coding: utf-8 -*-
"""Starter Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XO7fRtqraamz77JDZ8kqE0f1K8C8dfBq

# 1. Loading data and setting up folders
"""

#This cell is purely for loading the data and setting the directories for convenience

!wget --no-check-certificate \
https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
-O /tmp/cats_and_dogs_filtered.zip

#This loads in the dataset you'll be using for this project.
# ---UNZIP FILE HERE---

base_dir = '/tmp/cats_and_dogs_filtered'
train_dir = os.path.join(base_dir, 'train')  #some of this data will be split for validation later
testing_dir = os.path.join(base_dir, 'validation')  #this data will be reserved for testing despite the directory's name

# Directory with our training cat pictures
# ---INSERT CODE HERE---

# Directory with our training dog pictures
# ---INSERT CODE HERE---

# Directory with our validation cat pictures
# ---INSERT CODE HERE---

# Directory with our validation dog pictures
# ---INSERT CODE HERE---

# Cool commands to list our image files

os.chdir('dogs')
print(os.listdir())

"""# 2. Resizing the images"""

# Commented out IPython magic to ensure Python compatibility.
# Import tools

import numpy as np  #storing the data using this
import cv2  #for reading the images into grayscale vectors
from PIL import Image  #used to manipulate the images into the appropriate sizes
import matplotlib.pyplot as plt
# %matplotlib inline

from keras.preprocessing.image import ImageDataGenerator as IDG  #keras's built in image augmentor, which we can use to specify image size and such

size = (160, 160)  #the new size of each image after resizing. Dimensions are still up in the air

#using IDG, make an augmentor with the parameters indicating what augmentations can take place.


normal_generator = IDG(rescale=1./255)  #no need to have augmentation parameters since the model isn't being trained to fit data generated by this. 
                                        # Just normalize the data appropriately.

#we'll use our augmented data generator instead of just extracting our training data. IDG has something perfect for this,
#considering we have the directories already.

#needed data generators
#TRAINING GENERATOR:
training_generator = normal_generator.flow_from_directory(train_dir,
                                                       target_size=size,  #force resizes all input images, super nice.
                                                       batch_size=20,
                                                       class_mode='binary',
                                                       subset='training')  

#VALIDATION GENERATOR:
# ---INSERT CODE HERE---

#TESTING GENERATOR:
# ---INSERT CODE HERE---

#This is why we have the data separated into two subdirectories in the training and validation directories.
#The way the data can tell the cats from the dogs is simply due to the fact that they are in two different
#sub directories as they flow in from their main directories. The generator automatically applies labels to
#them this way. Super useful. And since validation and training have the same subdirectories, the labels will
#be the same as well, which is required.

"""# 3. Creating the neural network model (cnn)"""

from tensorflow.keras.models import Sequential as seq
from tensorflow.keras.layers import Dense, Conv2D, Flatten,  MaxPooling2D, Dropout
#Standard model creation that can be used for most projects. You can play around with layers if you would like to increase or decrease accuracy.
def createModel():
  model = seq()
  model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(size[0],size[1],3)))    #The 3 indicates RGB, since we don't need to grayscale.
  model.add(MaxPooling2D((2,2)))  #reduces dimensionality for computational ease
  
  model.add(Conv2D(64, kernel_size=3, activation='relu'))
  model.add(MaxPooling2D((2,2)))

  #Add Code 
  
  model.add(Dropout(0.5))
  
  model.add(Flatten())  #allows the data from the previous layer to be fed into a standard dense layer
  
  #the rest of these is architecture of the normal deep neural network

  model.add(Dense(1024, activation='relu'))
  model.add(Dense(1, activation='--Insert Command--')) 
  
  print(model.summary())
  return model

myModel = createModel()

"""Note that recall and precision, in this case, are not very important. The errors of identifying a cat as a dog and vice versa are of equal consequence; thus, there is no real reason to check for recall and precision, and relying on accuracy is a good enough metric to judge our CNN. Based on this, we can now compile and train our model with accuracy as its sole metric.

# 4. Training the data
"""

from tensorflow.keras.optimizers import RMSprop  #special kind of optimizer that allows 

myModel.compile(loss='binary_crossentropy',
                optimizer=RMSprop(lr=2e-4),  #learning rate of 0.0002 originally
                metrics=['accuracy'])

t_history = myModel.fit_generator(training_generator, 
                                  validation_data=validation_generator,
                                  validation_steps=40,
                                  epochs=100,
                                  steps_per_epoch=80)

"""# 5. Checking our model's stats"""

testing_loss, testing_acc = myModel.evaluate_generator(testing_generator)
#just for you to see loss and accuracy(Note: these are decimals out of 1)
print("Testing loss: {}".format(testing_loss))
print("Testing accuracy: {}".format(testing_acc))

"""# 6. Saving the model"""

#make a directory for saving models to

#Change into the "/content" directory using os.chdir
#INSERT CODE HERE

#Make a directory where you will save your models using os.mkdir
#INSERT CODE HERE

#save the current model to a file

#Change into the directory where you will save your models
#INSERT CODE HERE

model_num = 3  #change this manually after the run. this was the best model we had
myModel.save("model_{}.h5".format(model_num))  #remember to download it locally

"""# 7. Try out the model!"""

#Import the Image module from PIL
#INSERT CODE HERE
import requests

def getImage2(url):  
  im = Image.open(requests.get(url, stream=True).raw)
  return im

# Commented out IPython magic to ensure Python compatibility.
#Import matplotlib.pyplot using the alias plt
#INSERT CODE HERE

#Import numpy using the alias np
#INSERT CODE HERE

# %matplotlib inline

#Create your own command line message using the print function, 
#it should say something along the lines of "give me an image to classify"
#INSERT CODE HERE

#Ask the user for an input URL link using the input() function and convert the 
#input into a string. Save this string into a variable of your choice
#INSERT CODE HERE 

#Call the getImage2 function using your URL variable defined above and save into 
#a variable called retr_img. This will return an image
#INSERT CODE HERE

#Display your image using the imshow function within the matplotlib.pyplot library 
#INSERT CODE HERE

#adjust the image appropriately
retr_img = retr_img.resize(size)
retr_img = np.divide(np.array(retr_img),255)

retr_img = retr_img.reshape(1,size[0],size[1],3)

#print the prediction!
print("Classified as cat.") if myModel.predict(retr_img)[0][0] <= 0.5 else print("Classified as dog.")